from transformers import pipeline
import pandas as pd

# Modelleri Ã¶nceden yÃ¼kle
print("Modeller yÃ¼kleniyor...")
model1 = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)
model2 = pipeline("zero-shot-classification", model="roberta-large-mnli", device=0)
model3 = pipeline("zero-shot-classification", model="microsoft/deberta-large-mnli", device=0)

models = [model1, model2, model3]
weights = [0.4, 0.3, 0.3]
candidate_labels = ["factual information", "misinformation", "unverified claim"]

def get_predictions(models, text, candidate_labels):
    predictions = []
    for model in models:
        result = model(text, candidate_labels)
        predictions.append(result["labels"][0])
    return predictions

def weighted_ensemble_predict(models, weights, text, candidate_labels):
    vote_counts = {}
    for model, weight in zip(models, weights):
        result = model(text, candidate_labels)
        for label, score in zip(result["labels"], result["scores"]):
            vote_counts[label] = vote_counts.get(label, 0) + score * weight
    return max(vote_counts.items(), key=lambda x: x[1])[0]


def ensemble_prediction(text):
    if not isinstance(text, str) or not text.strip():
        return "LABEL_UNKNOWN"
    pred = weighted_ensemble_predict(models, weights, text, candidate_labels)
    if "misinformation" in pred:
        return "misinformation"
    elif "factual information" in pred:
        return "true information"
    else:
        return "unverified claim"

def detect_misinformation(df):
    print("\nğŸ” Ensemble modellerle yanlÄ±ÅŸ bilgi tespiti yapÄ±lÄ±yor...")
    df["misinformation_label"] = df["cleaned_text"].apply(ensemble_prediction)
    print("\nâœ… YanlÄ±ÅŸ bilgi tespiti tamamlandÄ±. Ä°lk 5 sonuÃ§:")
    print(df[["cleaned_text", "misinformation_label"]].head())
    return df

from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def evaluate_misinformation_detection(df):
    """
    DoÄŸru ve tahmin edilen etiketlere gÃ¶re sÄ±nÄ±flandÄ±rma performansÄ±nÄ± deÄŸerlendirir.
    """
    if "label" not in df.columns or "misinformation_label" not in df.columns:
        print("âš ï¸ 'label' ve 'misinformation_label' sÃ¼tunlarÄ± bulunamadÄ±.")
        return

    y_true = df["label"]
    y_pred = df["misinformation_label"]

    print("\nğŸ“‹ SÄ±nÄ±flandÄ±rma Raporu:")
    print(classification_report(y_true, y_pred, digits=3))

    acc = accuracy_score(y_true, y_pred)
    print(f"\nğŸ¯ DoÄŸruluk (Accuracy): {acc:.2%}")

    # Confusion matrix gÃ¶rselleÅŸtirme
    cm = confusion_matrix(y_true, y_pred, labels=["misinformation", "true information", "unverified claim"])
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=["misinformation", "true information", "unverified claim"],
                yticklabels=["misinformation", "true information", "unverified claim"])
    plt.title("Confusion Matrix")
    plt.xlabel("Tahmin")
    plt.ylabel("GerÃ§ek")
    plt.tight_layout()
    plt.show()

