import pandas as pd
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score
from transformers import pipeline
from bertopic import BERTopic
import matplotlib.pyplot as plt
import seaborn as sns
import os

def evaluate_models():
    print("ğŸ“Š Modeller deÄŸerlendiriliyor...")

    data_path = "data/test_dataset_1000.csv"

    if not os.path.exists(data_path):
        print(f"Hata: Veri dosyasÄ± bulunamadÄ± -> {data_path}")
        return

    # CSV dosyasÄ±nÄ± doÄŸru ÅŸekilde oku
    df = pd.read_csv(data_path, encoding="windows-1254")

    if "cleaned_text" not in df.columns or "label" not in df.columns:
        print("Hata: 'cleaned_text' ve 'label' sÃ¼tunlarÄ± eksik!")
        print("Mevcut sÃ¼tunlar:", df.columns.tolist())
        return

    # 1. YanlÄ±ÅŸ Bilgi Tespiti Modeli DeÄŸerlendirmesi
    print("\nğŸ” YanlÄ±ÅŸ Bilgi Tespiti Modeli DeÄŸerlendirmesi:")
    misinformation_classifier = pipeline("zero-shot-classification", 
                                      model="facebook/bart-large-mnli", 
                                      device=0)

    candidate_labels = ["factual information", "misinformation", "unverified claim"]
    predicted_labels = []

    for text in df["cleaned_text"]:
        if not text.strip():
            predicted_labels.append("LABEL_UNKNOWN")
            continue

        prediction = misinformation_classifier(text, candidate_labels)
        top_label = prediction["labels"][0]

        if "misinformation" in top_label:
            label = "misinformation"
        elif "factual information" in top_label:
            label = "true information"
        else:
            label = "unverified claim"

        predicted_labels.append(label)

    print("\nğŸ“‹ YanlÄ±ÅŸ Bilgi Tespiti SÄ±nÄ±flandÄ±rma Raporu:")
    print(classification_report(df["label"], predicted_labels, digits=3))

    # 2. Duygu Analizi Modeli DeÄŸerlendirmesi
    print("\nğŸ˜Š Duygu Analizi Modeli DeÄŸerlendirmesi:")
    sentiment_analyzer = pipeline("sentiment-analysis")
    
    # EÄŸer veri setinde duygu etiketleri varsa
    if "sentiment" in df.columns:
        predicted_sentiments = []
        for text in df["cleaned_text"]:
            result = sentiment_analyzer(text)[0]
            predicted_sentiments.append(result["label"])

        print("\nğŸ“‹ Duygu Analizi SÄ±nÄ±flandÄ±rma Raporu:")
        print(classification_report(df["sentiment"], predicted_sentiments, digits=3))

    # 3. Konu Modelleme DeÄŸerlendirmesi
    print("\nğŸ“š Konu Modelleme DeÄŸerlendirmesi:")
    topic_model = BERTopic(language="english")
    
    # Konu modelleme iÃ§in metinleri dÃ¶nÃ¼ÅŸtÃ¼r
    topics, probabilities = topic_model.fit_transform(df["cleaned_text"])
    
    # Konu daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rselleÅŸtir
    plt.figure(figsize=(12, 6))
    sns.countplot(x=topics, palette="viridis")
    plt.title("Konu DaÄŸÄ±lÄ±mÄ±")
    plt.xlabel("Konu ID")
    plt.ylabel("Tweet SayÄ±sÄ±")
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    # GÃ¶rselleÅŸtirmeyi kaydet
    if not os.path.exists("visualizations"):
        os.makedirs("visualizations")
    plt.savefig("visualizations/topic_distribution.png")
    plt.close()

    # Konu kalitesi metrikleri
    topic_info = topic_model.get_topic_info()
    print("\nğŸ“Š Konu Modelleme Metrikleri:")
    print(f"Toplam Konu SayÄ±sÄ±: {len(topic_info)}")
    print(f"Ortalama Konu Boyutu: {topic_info['Count'].mean():.2f}")
    print(f"En BÃ¼yÃ¼k Konu Boyutu: {topic_info['Count'].max()}")
    print(f"En KÃ¼Ã§Ã¼k Konu Boyutu: {topic_info['Count'].min()}")

    print("\nâœ… TÃ¼m modeller deÄŸerlendirildi ve sonuÃ§lar kaydedildi.")

if __name__ == "__main__":
    evaluate_models()