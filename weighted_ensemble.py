from transformers import pipeline
import pandas as pd
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
import os

print("Modeller yÃ¼kleniyor...")
model1 = pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=0)
model2 = pipeline("zero-shot-classification", model="roberta-large-mnli", device=0)
model3 = pipeline("zero-shot-classification", model="microsoft/deberta-large-mnli", device=0)

models = [model1, model2, model3]
weights = [0.4, 0.3, 0.3]  # AÄŸÄ±rlÄ±klar toplamÄ± 1

candidate_labels = [
    "factual information", "misinformation", "unverified claim"
]

def get_predictions(models, text, candidate_labels):
    predictions = []
    for model in models:
        result = model(text, candidate_labels)
        predictions.append(result["labels"][0])
    return predictions

def weighted_ensemble_predict(models, weights, text, candidate_labels):
    predictions = get_predictions(models, text, candidate_labels)
    vote_counts = {}
    for pred, weight in zip(predictions, weights):
        if pred not in vote_counts:
            vote_counts[pred] = 0
        vote_counts[pred] += weight
    return max(vote_counts.items(), key=lambda x: x[1])[0]

def ensemble_prediction(text):
    if not isinstance(text, str) or not text.strip():
        return "LABEL_UNKNOWN"

    pred = weighted_ensemble_predict(models, weights, text, candidate_labels)

    if "misinformation" in pred:
        return "misinformation"
    elif "factual information" in pred:
        return "true information"
    else:
        return "unverified claim"

def detect_misinformation(df):
    print("\nEnsemble modellerle yanlÄ±ÅŸ bilgi tespiti yapÄ±lÄ±yor...")
    
    # Batch boyutu
    BATCH_SIZE = 32
    
    # Batch'ler halinde iÅŸle
    all_predictions = []
    total_batches = len(df) // BATCH_SIZE + (1 if len(df) % BATCH_SIZE != 0 else 0)
    
    for i in range(0, len(df), BATCH_SIZE):
        batch = df["cleaned_text"].iloc[i:i+BATCH_SIZE]
        batch_predictions = []
        
        for text in batch:
            if not isinstance(text, str) or not text.strip():
                batch_predictions.append("LABEL_UNKNOWN")
                continue
                
            pred = weighted_ensemble_predict(models, weights, text, candidate_labels)
            
            if "misinformation" in pred:
                label = "misinformation"
            elif "factual information" in pred:
                label = "true information"
            else:
                label = "unverified claim"
                
            batch_predictions.append(label)
            
        all_predictions.extend(batch_predictions)
        print(f"\rÄ°ÅŸlenen batch: {i//BATCH_SIZE + 1}/{total_batches}", end="")
    
    print("\nTahminler tamamlandÄ±.")
    df["misinformation_label"] = all_predictions
    print("\nÄ°lk 5 Ã¶rnek:")
    print(df[["cleaned_text", "misinformation_label"]].head())
    return df

def evaluate_models(df):
    print("\nğŸ“Š Modeller deÄŸerlendiriliyor...")

    if "cleaned_text" not in df.columns or "label" not in df.columns:
        print("Hata: 'cleaned_text' ve 'label' sÃ¼tunlarÄ± eksik!")
        print("Mevcut sÃ¼tunlar:", df.columns.tolist())
        return

    # 1. Ensemble Model DeÄŸerlendirmesi
    print("\nğŸ” Ensemble Model DeÄŸerlendirmesi:")
    predicted_labels = df["misinformation_label"]
    true_labels = df["label"]

    # DoÄŸruluk oranÄ±nÄ± hesapla
    accuracy = accuracy_score(true_labels, predicted_labels)
    print(f"\nğŸ“ˆ Ensemble Model DoÄŸruluk OranÄ±: {accuracy:.2%}")

    print("\nğŸ“‹ Ensemble Model SÄ±nÄ±flandÄ±rma Raporu:")
    print(classification_report(true_labels, predicted_labels, digits=3))

    # 2. Duygu Analizi Modeli DeÄŸerlendirmesi
    print("\nğŸ˜Š Duygu Analizi Modeli DeÄŸerlendirmesi:")
    sentiment_analyzer = pipeline("sentiment-analysis")
    
    # EÄŸer veri setinde duygu etiketleri varsa
    if "sentiment" in df.columns:
        predicted_sentiments = []
        for text in df["cleaned_text"]:
            result = sentiment_analyzer(text)[0]
            predicted_sentiments.append(result["label"])

        print("\nğŸ“‹ Duygu Analizi SÄ±nÄ±flandÄ±rma Raporu:")
        print(classification_report(df["sentiment"], predicted_sentiments, digits=3))

    # 3. Konu Modelleme DeÄŸerlendirmesi
    print("\nğŸ“š Konu Modelleme DeÄŸerlendirmesi:")
    from bertopic import BERTopic
    topic_model = BERTopic(language="english")
    
    # Konu modelleme iÃ§in metinleri dÃ¶nÃ¼ÅŸtÃ¼r
    topics, probabilities = topic_model.fit_transform(df["cleaned_text"])
    
    # Konu daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rselleÅŸtir
    plt.figure(figsize=(12, 6))
    sns.countplot(x=topics, palette="viridis")
    plt.title("Konu DaÄŸÄ±lÄ±mÄ±")
    plt.xlabel("Konu ID")
    plt.ylabel("Tweet SayÄ±sÄ±")
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    # GÃ¶rselleÅŸtirmeyi kaydet
    if not os.path.exists("visualizations"):
        os.makedirs("visualizations")
    plt.savefig("visualizations/topic_distribution.png")
    plt.close()

    # Konu kalitesi metrikleri
    topic_info = topic_model.get_topic_info()
    print("\nğŸ“Š Konu Modelleme Metrikleri:")
    print(f"Toplam Konu SayÄ±sÄ±: {len(topic_info)}")
    print(f"Ortalama Konu Boyutu: {topic_info['Count'].mean():.2f}")
    print(f"En BÃ¼yÃ¼k Konu Boyutu: {topic_info['Count'].max()}")
    print(f"En KÃ¼Ã§Ã¼k Konu Boyutu: {topic_info['Count'].min()}")

    print("\nâœ… TÃ¼m modeller deÄŸerlendirildi ve sonuÃ§lar kaydedildi.")

if __name__ == "__main__":
    # CSV dosyasÄ±nÄ± daha esnek bir ÅŸekilde oku
    df = pd.read_csv("data/test_dataset_1000.csv", 
                     encoding="windows-1254",
                     quoting=1,  # QUOTE_ALL modu
                     escapechar='\\')  # KaÃ§Ä±ÅŸ karakteri
    
    # SÃ¼tun isimlerini dÃ¼zelt
    df.columns = ['tweet_id', 'cleaned_text', 'label']
    
    df = detect_misinformation(df)
    evaluate_models(df)
    df.to_csv("results/ensemble_predictions.csv", index=False)

